{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import multinomial\n",
    "from numpy import log, exp\n",
    "from numpy import argmax\n",
    "import json\n",
    "import numpy as np\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGroupProcess:\n",
    "    def __init__(self, K=8, alpha=0.1, beta=0.1, n_iters=30):\n",
    "        '''\n",
    "        A MovieGroupProcess is a conceptual model introduced by Yin and Wang 2014 to\n",
    "        describe their Gibbs sampling algorithm for a Dirichlet Mixture Model for the\n",
    "        clustering short text documents.\n",
    "        Reference: http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n",
    "        Imagine a professor is leading a film class. At the start of the class, the students\n",
    "        are randomly assigned to K tables. Before class begins, the students make lists of\n",
    "        their favorite films. The teacher reads the role n_iters times. When\n",
    "        a student is called, the student must select a new table satisfying either:\n",
    "            1) The new table has more students than the current table.\n",
    "        OR\n",
    "            2) The new table has students with similar lists of favorite movies.\n",
    "        :param K: int\n",
    "            Upper bound on the number of possible clusters. Typically many fewer\n",
    "        :param alpha: float between 0 and 1\n",
    "            Alpha controls the probability that a student will join a table that is currently empty\n",
    "            When alpha is 0, no one will join an empty table.\n",
    "        :param beta: float between 0 and 1\n",
    "            Beta controls the student's affinity for other students with similar interests. A low beta means\n",
    "            that students desire to sit with students of similar interests. A high beta means they are less\n",
    "            concerned with affinity and are more influenced by the popularity of a table\n",
    "        :param n_iters:\n",
    "        '''\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.n_iters = n_iters\n",
    "\n",
    "        # slots for computed variables\n",
    "        self.number_docs = None\n",
    "        self.vocab_size = None\n",
    "        self.cluster_doc_count = [0 for _ in range(K)]\n",
    "        self.cluster_word_count = [0 for _ in range(K)]\n",
    "        self.cluster_word_distribution = [{} for i in range(K)]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_data(K, alpha, beta, D, vocab_size, cluster_doc_count, cluster_word_count, cluster_word_distribution):\n",
    "        '''\n",
    "        Reconstitute a MovieGroupProcess from previously fit data\n",
    "        :param K:\n",
    "        :param alpha:\n",
    "        :param beta:\n",
    "        :param D:\n",
    "        :param vocab_size:\n",
    "        :param cluster_doc_count:\n",
    "        :param cluster_word_count:\n",
    "        :param cluster_word_distribution:\n",
    "        :return:\n",
    "        '''\n",
    "        mgp = MovieGroupProcess(K, alpha, beta, n_iters=30)\n",
    "        mgp.number_docs = D\n",
    "        mgp.vocab_size = vocab_size\n",
    "        mgp.cluster_doc_count = cluster_doc_count\n",
    "        mgp.cluster_word_count = cluster_word_count\n",
    "        mgp.cluster_word_distribution = cluster_word_distribution\n",
    "        return mgp\n",
    "\n",
    "    @staticmethod\n",
    "    def _sample(p):\n",
    "        '''\n",
    "        Sample with probability vector p from a multinomial distribution\n",
    "        :param p: list\n",
    "            List of probabilities representing probability vector for the multinomial distribution\n",
    "        :return: int\n",
    "            index of randomly selected output\n",
    "        '''\n",
    "        return [i for i, entry in enumerate(multinomial(1, p)) if entry != 0][0]\n",
    "\n",
    "    def fit(self, docs, vocab_size):\n",
    "        '''\n",
    "        Cluster the input documents\n",
    "        :param docs: list of list\n",
    "            list of lists containing the unique token set of each document\n",
    "        :param V: total vocabulary size for each document\n",
    "        :return: list of length len(doc)\n",
    "            cluster label for each document\n",
    "        '''\n",
    "        alpha, beta, K, n_iters, V = self.alpha, self.beta, self.K, self.n_iters, vocab_size\n",
    "\n",
    "        D = len(docs)\n",
    "        self.number_docs = D\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # unpack to easy var names\n",
    "        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n",
    "        cluster_count = K\n",
    "        d_z = [None for i in range(len(docs))]\n",
    "\n",
    "        # initialize the clusters\n",
    "        for i, doc in enumerate(docs):\n",
    "\n",
    "            # choose a random  initial cluster for the doc\n",
    "            z = self._sample([1.0 / K for _ in range(K)])\n",
    "            d_z[i] = z\n",
    "            m_z[z] += 1\n",
    "            n_z[z] += len(doc)\n",
    "\n",
    "            for word in doc:\n",
    "                #print(word)\n",
    "                if word not in n_z_w[z]:\n",
    "                    n_z_w[z][word] = 0\n",
    "                n_z_w[z][word] += 1\n",
    "        #print(n_z_w)\n",
    "        for _iter in range(n_iters):\n",
    "            total_transfers = 0\n",
    "\n",
    "            for i, doc in enumerate(docs):\n",
    "\n",
    "                # remove the doc from it's current cluster\n",
    "                z_old = d_z[i]\n",
    "\n",
    "                m_z[z_old] -= 1\n",
    "                n_z[z_old] -= len(doc)\n",
    "\n",
    "                for word in doc:\n",
    "                    n_z_w[z_old][word] -= 1\n",
    "\n",
    "                    # compact dictionary to save space\n",
    "                    if n_z_w[z_old][word] == 0:\n",
    "                        del n_z_w[z_old][word]\n",
    "\n",
    "                # draw sample from distribution to find new cluster\n",
    "                p = self.score(doc)\n",
    "                z_new = self._sample(p)\n",
    "\n",
    "                # transfer doc to the new cluster\n",
    "                if z_new != z_old:\n",
    "                    total_transfers += 1\n",
    "\n",
    "                d_z[i] = z_new\n",
    "                m_z[z_new] += 1\n",
    "                n_z[z_new] += len(doc)\n",
    "\n",
    "                for word in doc:\n",
    "                    if word not in n_z_w[z_new]:\n",
    "                        n_z_w[z_new][word] = 0\n",
    "                    n_z_w[z_new][word] += 1\n",
    "\n",
    "            cluster_count_new = sum([1 for v in m_z if v > 0])\n",
    "            print(\"In stage %d: transferred %d clusters with %d clusters populated\" % (\n",
    "            _iter, total_transfers, cluster_count_new))\n",
    "            if total_transfers == 0 and cluster_count_new == cluster_count and _iter>25:\n",
    "                print(\"Converged.  Breaking out.\")\n",
    "                break\n",
    "            self.cluster_count = cluster_count_new\n",
    "        self.cluster_word_distribution = n_z_w\n",
    "        return d_z\n",
    "\n",
    "    def score(self, doc):\n",
    "        '''\n",
    "        Score a document\n",
    "        Implements formula (3) of Yin and Wang 2014.\n",
    "        http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n",
    "        :param doc: list[str]: The doc token stream\n",
    "        :return: list[float]: A length K probability vector where each component represents\n",
    "                              the probability of the document appearing in a particular cluster\n",
    "        '''\n",
    "        alpha, beta, K, V, D = self.alpha, self.beta, self.K, self.vocab_size, self.number_docs\n",
    "        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n",
    "\n",
    "        p = [0 for _ in range(K)]\n",
    "\n",
    "        #  We break the formula into the following pieces\n",
    "        #  p = N1*N2/(D1*D2) = exp(lN1 - lD1 + lN2 - lD2)\n",
    "        #  lN1 = log(m_z[z] + alpha)\n",
    "        #  lN2 = log(D - 1 + K*alpha)\n",
    "        #  lN2 = log(product(n_z_w[w] + beta)) = sum(log(n_z_w[w] + beta))\n",
    "        #  lD2 = log(product(n_z[d] + V*beta + i -1)) = sum(log(n_z[d] + V*beta + i -1))\n",
    "\n",
    "        lD1 = log(D - 1 + K * alpha)\n",
    "        doc_size = len(doc)\n",
    "        #print(doc_size)\n",
    "        for label in range(K):\n",
    "            lN1 = log(m_z[label] + alpha)\n",
    "            lN2 = 0\n",
    "            lD2 = 0\n",
    "            for word in doc:\n",
    "                lN2 += log(n_z_w[label].get(word, 0) + beta)\n",
    "            for j in range(1, doc_size +1):\n",
    "                lD2 += log(n_z[label] + V * beta + j - 1)\n",
    "            #print(lD2)\n",
    "            p[label] = exp(lN1 - lD1 + lN2 - lD2)\n",
    "\n",
    "        # normalize the probability vector\n",
    "        #print(p)\n",
    "        pnorm = sum(p)\n",
    "        pnorm = pnorm if pnorm>0 else 1\n",
    "        return [pp/pnorm for pp in p]\n",
    "\n",
    "    def choose_best_label(self, doc):\n",
    "        '''\n",
    "        Choose the highest probability label for the input document\n",
    "        :param doc: list[str]: The doc token stream\n",
    "        :return:\n",
    "        '''\n",
    "        p = self.score(doc)\n",
    "        return argmax(p),max(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MovieGroupProcess(K=10, alpha=0.1, beta=0.01, n_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 235 clusters with 10 clusters populated\n",
      "In stage 1: transferred 77 clusters with 9 clusters populated\n",
      "In stage 2: transferred 28 clusters with 10 clusters populated\n",
      "In stage 3: transferred 14 clusters with 10 clusters populated\n",
      "In stage 4: transferred 19 clusters with 10 clusters populated\n",
      "In stage 5: transferred 14 clusters with 10 clusters populated\n",
      "In stage 6: transferred 13 clusters with 10 clusters populated\n",
      "In stage 7: transferred 11 clusters with 10 clusters populated\n",
      "In stage 8: transferred 13 clusters with 10 clusters populated\n",
      "In stage 9: transferred 13 clusters with 10 clusters populated\n",
      "In stage 10: transferred 11 clusters with 10 clusters populated\n",
      "In stage 11: transferred 15 clusters with 10 clusters populated\n",
      "In stage 12: transferred 20 clusters with 10 clusters populated\n",
      "In stage 13: transferred 14 clusters with 10 clusters populated\n",
      "In stage 14: transferred 11 clusters with 10 clusters populated\n",
      "In stage 15: transferred 15 clusters with 10 clusters populated\n",
      "In stage 16: transferred 15 clusters with 10 clusters populated\n",
      "In stage 17: transferred 23 clusters with 10 clusters populated\n",
      "In stage 18: transferred 20 clusters with 10 clusters populated\n",
      "In stage 19: transferred 15 clusters with 10 clusters populated\n",
      "In stage 20: transferred 16 clusters with 10 clusters populated\n",
      "In stage 21: transferred 16 clusters with 10 clusters populated\n",
      "In stage 22: transferred 14 clusters with 10 clusters populated\n",
      "In stage 23: transferred 15 clusters with 10 clusters populated\n",
      "In stage 24: transferred 14 clusters with 10 clusters populated\n",
      "In stage 25: transferred 16 clusters with 10 clusters populated\n",
      "In stage 26: transferred 20 clusters with 10 clusters populated\n",
      "In stage 27: transferred 18 clusters with 10 clusters populated\n",
      "In stage 28: transferred 18 clusters with 10 clusters populated\n",
      "In stage 29: transferred 16 clusters with 10 clusters populated\n",
      "In stage 30: transferred 14 clusters with 10 clusters populated\n",
      "In stage 31: transferred 11 clusters with 10 clusters populated\n",
      "In stage 32: transferred 17 clusters with 10 clusters populated\n",
      "In stage 33: transferred 17 clusters with 10 clusters populated\n",
      "In stage 34: transferred 17 clusters with 10 clusters populated\n",
      "In stage 35: transferred 17 clusters with 10 clusters populated\n",
      "In stage 36: transferred 14 clusters with 10 clusters populated\n",
      "In stage 37: transferred 22 clusters with 10 clusters populated\n",
      "In stage 38: transferred 15 clusters with 10 clusters populated\n",
      "In stage 39: transferred 15 clusters with 10 clusters populated\n",
      "In stage 40: transferred 14 clusters with 10 clusters populated\n",
      "In stage 41: transferred 14 clusters with 10 clusters populated\n",
      "In stage 42: transferred 13 clusters with 10 clusters populated\n",
      "In stage 43: transferred 12 clusters with 10 clusters populated\n",
      "In stage 44: transferred 19 clusters with 10 clusters populated\n",
      "In stage 45: transferred 22 clusters with 10 clusters populated\n",
      "In stage 46: transferred 16 clusters with 10 clusters populated\n",
      "In stage 47: transferred 14 clusters with 10 clusters populated\n",
      "In stage 48: transferred 17 clusters with 10 clusters populated\n",
      "In stage 49: transferred 20 clusters with 10 clusters populated\n",
      "In stage 50: transferred 17 clusters with 10 clusters populated\n",
      "In stage 51: transferred 10 clusters with 10 clusters populated\n",
      "In stage 52: transferred 11 clusters with 10 clusters populated\n",
      "In stage 53: transferred 16 clusters with 10 clusters populated\n",
      "In stage 54: transferred 17 clusters with 10 clusters populated\n",
      "In stage 55: transferred 19 clusters with 10 clusters populated\n",
      "In stage 56: transferred 12 clusters with 10 clusters populated\n",
      "In stage 57: transferred 12 clusters with 10 clusters populated\n",
      "In stage 58: transferred 13 clusters with 10 clusters populated\n",
      "In stage 59: transferred 18 clusters with 10 clusters populated\n",
      "In stage 60: transferred 17 clusters with 10 clusters populated\n",
      "In stage 61: transferred 19 clusters with 10 clusters populated\n",
      "In stage 62: transferred 8 clusters with 10 clusters populated\n",
      "In stage 63: transferred 14 clusters with 10 clusters populated\n",
      "In stage 64: transferred 21 clusters with 10 clusters populated\n",
      "In stage 65: transferred 19 clusters with 10 clusters populated\n",
      "In stage 66: transferred 15 clusters with 10 clusters populated\n",
      "In stage 67: transferred 15 clusters with 10 clusters populated\n",
      "In stage 68: transferred 17 clusters with 10 clusters populated\n",
      "In stage 69: transferred 16 clusters with 10 clusters populated\n",
      "In stage 70: transferred 18 clusters with 10 clusters populated\n",
      "In stage 71: transferred 26 clusters with 10 clusters populated\n",
      "In stage 72: transferred 22 clusters with 10 clusters populated\n",
      "In stage 73: transferred 21 clusters with 10 clusters populated\n",
      "In stage 74: transferred 11 clusters with 10 clusters populated\n",
      "In stage 75: transferred 10 clusters with 10 clusters populated\n",
      "In stage 76: transferred 12 clusters with 10 clusters populated\n",
      "In stage 77: transferred 15 clusters with 10 clusters populated\n",
      "In stage 78: transferred 14 clusters with 10 clusters populated\n",
      "In stage 79: transferred 12 clusters with 10 clusters populated\n",
      "In stage 80: transferred 16 clusters with 10 clusters populated\n",
      "In stage 81: transferred 16 clusters with 10 clusters populated\n",
      "In stage 82: transferred 13 clusters with 10 clusters populated\n",
      "In stage 83: transferred 13 clusters with 10 clusters populated\n",
      "In stage 84: transferred 16 clusters with 10 clusters populated\n",
      "In stage 85: transferred 16 clusters with 10 clusters populated\n",
      "In stage 86: transferred 8 clusters with 10 clusters populated\n",
      "In stage 87: transferred 13 clusters with 10 clusters populated\n",
      "In stage 88: transferred 12 clusters with 10 clusters populated\n",
      "In stage 89: transferred 14 clusters with 10 clusters populated\n",
      "In stage 90: transferred 13 clusters with 10 clusters populated\n",
      "In stage 91: transferred 10 clusters with 10 clusters populated\n",
      "In stage 92: transferred 16 clusters with 10 clusters populated\n",
      "In stage 93: transferred 16 clusters with 10 clusters populated\n",
      "In stage 94: transferred 16 clusters with 10 clusters populated\n",
      "In stage 95: transferred 13 clusters with 10 clusters populated\n",
      "In stage 96: transferred 13 clusters with 10 clusters populated\n",
      "In stage 97: transferred 13 clusters with 10 clusters populated\n",
      "In stage 98: transferred 19 clusters with 10 clusters populated\n",
      "In stage 99: transferred 15 clusters with 10 clusters populated\n",
      "In stage 100: transferred 17 clusters with 10 clusters populated\n",
      "In stage 101: transferred 11 clusters with 10 clusters populated\n",
      "In stage 102: transferred 15 clusters with 10 clusters populated\n",
      "In stage 103: transferred 18 clusters with 10 clusters populated\n",
      "In stage 104: transferred 15 clusters with 10 clusters populated\n",
      "In stage 105: transferred 15 clusters with 10 clusters populated\n",
      "In stage 106: transferred 18 clusters with 10 clusters populated\n",
      "In stage 107: transferred 18 clusters with 10 clusters populated\n",
      "In stage 108: transferred 14 clusters with 10 clusters populated\n",
      "In stage 109: transferred 13 clusters with 10 clusters populated\n",
      "In stage 110: transferred 15 clusters with 10 clusters populated\n",
      "In stage 111: transferred 15 clusters with 10 clusters populated\n",
      "In stage 112: transferred 14 clusters with 10 clusters populated\n",
      "In stage 113: transferred 8 clusters with 10 clusters populated\n",
      "In stage 114: transferred 14 clusters with 10 clusters populated\n",
      "In stage 115: transferred 14 clusters with 10 clusters populated\n",
      "In stage 116: transferred 15 clusters with 10 clusters populated\n",
      "In stage 117: transferred 13 clusters with 10 clusters populated\n",
      "In stage 118: transferred 8 clusters with 10 clusters populated\n",
      "In stage 119: transferred 11 clusters with 10 clusters populated\n",
      "In stage 120: transferred 13 clusters with 10 clusters populated\n",
      "In stage 121: transferred 13 clusters with 10 clusters populated\n",
      "In stage 122: transferred 15 clusters with 10 clusters populated\n",
      "In stage 123: transferred 21 clusters with 10 clusters populated\n",
      "In stage 124: transferred 24 clusters with 10 clusters populated\n",
      "In stage 125: transferred 14 clusters with 10 clusters populated\n",
      "In stage 126: transferred 14 clusters with 10 clusters populated\n",
      "In stage 127: transferred 14 clusters with 10 clusters populated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 128: transferred 9 clusters with 10 clusters populated\n",
      "In stage 129: transferred 13 clusters with 10 clusters populated\n",
      "In stage 130: transferred 17 clusters with 10 clusters populated\n",
      "In stage 131: transferred 17 clusters with 10 clusters populated\n",
      "In stage 132: transferred 15 clusters with 10 clusters populated\n",
      "In stage 133: transferred 16 clusters with 10 clusters populated\n",
      "In stage 134: transferred 19 clusters with 10 clusters populated\n",
      "In stage 135: transferred 15 clusters with 10 clusters populated\n",
      "In stage 136: transferred 10 clusters with 10 clusters populated\n",
      "In stage 137: transferred 14 clusters with 10 clusters populated\n",
      "In stage 138: transferred 14 clusters with 10 clusters populated\n",
      "In stage 139: transferred 11 clusters with 10 clusters populated\n",
      "In stage 140: transferred 16 clusters with 10 clusters populated\n",
      "In stage 141: transferred 18 clusters with 10 clusters populated\n",
      "In stage 142: transferred 16 clusters with 10 clusters populated\n",
      "In stage 143: transferred 18 clusters with 10 clusters populated\n",
      "In stage 144: transferred 14 clusters with 10 clusters populated\n",
      "In stage 145: transferred 19 clusters with 10 clusters populated\n",
      "In stage 146: transferred 20 clusters with 10 clusters populated\n",
      "In stage 147: transferred 12 clusters with 10 clusters populated\n",
      "In stage 148: transferred 12 clusters with 10 clusters populated\n",
      "In stage 149: transferred 16 clusters with 10 clusters populated\n",
      "In stage 150: transferred 14 clusters with 10 clusters populated\n",
      "In stage 151: transferred 17 clusters with 10 clusters populated\n",
      "In stage 152: transferred 12 clusters with 10 clusters populated\n",
      "In stage 153: transferred 18 clusters with 10 clusters populated\n",
      "In stage 154: transferred 14 clusters with 10 clusters populated\n",
      "In stage 155: transferred 11 clusters with 10 clusters populated\n",
      "In stage 156: transferred 10 clusters with 10 clusters populated\n",
      "In stage 157: transferred 12 clusters with 10 clusters populated\n",
      "In stage 158: transferred 13 clusters with 10 clusters populated\n",
      "In stage 159: transferred 11 clusters with 10 clusters populated\n",
      "In stage 160: transferred 14 clusters with 10 clusters populated\n",
      "In stage 161: transferred 14 clusters with 10 clusters populated\n",
      "In stage 162: transferred 12 clusters with 10 clusters populated\n",
      "In stage 163: transferred 13 clusters with 10 clusters populated\n",
      "In stage 164: transferred 14 clusters with 10 clusters populated\n",
      "In stage 165: transferred 17 clusters with 10 clusters populated\n",
      "In stage 166: transferred 13 clusters with 10 clusters populated\n",
      "In stage 167: transferred 13 clusters with 10 clusters populated\n",
      "In stage 168: transferred 13 clusters with 10 clusters populated\n",
      "In stage 169: transferred 14 clusters with 10 clusters populated\n",
      "In stage 170: transferred 14 clusters with 10 clusters populated\n",
      "In stage 171: transferred 13 clusters with 10 clusters populated\n",
      "In stage 172: transferred 13 clusters with 10 clusters populated\n",
      "In stage 173: transferred 15 clusters with 10 clusters populated\n",
      "In stage 174: transferred 16 clusters with 10 clusters populated\n",
      "In stage 175: transferred 16 clusters with 10 clusters populated\n",
      "In stage 176: transferred 20 clusters with 10 clusters populated\n",
      "In stage 177: transferred 13 clusters with 10 clusters populated\n",
      "In stage 178: transferred 7 clusters with 10 clusters populated\n",
      "In stage 179: transferred 17 clusters with 10 clusters populated\n",
      "In stage 180: transferred 19 clusters with 10 clusters populated\n",
      "In stage 181: transferred 16 clusters with 10 clusters populated\n",
      "In stage 182: transferred 16 clusters with 10 clusters populated\n",
      "In stage 183: transferred 14 clusters with 10 clusters populated\n",
      "In stage 184: transferred 15 clusters with 10 clusters populated\n",
      "In stage 185: transferred 13 clusters with 10 clusters populated\n",
      "In stage 186: transferred 18 clusters with 10 clusters populated\n",
      "In stage 187: transferred 19 clusters with 10 clusters populated\n",
      "In stage 188: transferred 15 clusters with 10 clusters populated\n",
      "In stage 189: transferred 11 clusters with 10 clusters populated\n",
      "In stage 190: transferred 13 clusters with 10 clusters populated\n",
      "In stage 191: transferred 15 clusters with 10 clusters populated\n",
      "In stage 192: transferred 18 clusters with 10 clusters populated\n",
      "In stage 193: transferred 11 clusters with 10 clusters populated\n",
      "In stage 194: transferred 13 clusters with 10 clusters populated\n",
      "In stage 195: transferred 12 clusters with 10 clusters populated\n",
      "In stage 196: transferred 16 clusters with 10 clusters populated\n",
      "In stage 197: transferred 12 clusters with 10 clusters populated\n",
      "In stage 198: transferred 14 clusters with 10 clusters populated\n",
      "In stage 199: transferred 13 clusters with 10 clusters populated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(processed_docs,2772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hy822\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "#np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    token_list=[]\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            token_list.append(token)\n",
    "    return result,dict(zip(result,token_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_mapping(mapping_list):\n",
    "    #processed_ser= corpus.fillna(\"\").apply(lambda x: re.sub(r\"http[s]?\\:\\/\\/.[a-zA-Z0-9\\.\\/\\_?=%&#\\-\\+!]+\",\" \",x)).map(preprocess)\n",
    "    #processed_docs=[item[0] for item in processed_ser]\n",
    "    #mapping_list=[item[1] for item in processed_ser]\n",
    "    mapping_pairs=pd.concat([pd.DataFrame([(k,v) for k,v in d.items()]) for d in mapping_list])\n",
    "    mapping_pairs['count']=1\n",
    "    mapping121=mapping_pairs.groupby(by=[0,1]).count().reset_index().sort_values(by=[0,'count'],ascending=False).groupby(by=0).head(1)\n",
    "    mapping12many=mapping_pairs.drop(columns=['count']).drop_duplicates()\n",
    "    return mapping121,mapping12many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_fb_df=pd.read_csv(\"../data/facebook_Malawi.csv\",delimiter=\"|\",index_col=0)\n",
    "MI_tw_df=pd.read_csv(\"../data/twitter_Malawi.csv\",delimiter=\"|\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_ser = MI_fb_df['message'].fillna(\"\").apply(lambda x: re.sub(r\"http[s]?\\:\\/\\/.[a-zA-Z0-9\\.\\/\\_?=%&#\\-\\+!]+\",\" \",x)).map(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs=np.array([np.array(item[0]) for item in processed_ser])\n",
    "mapping_list=[item[1] for item in processed_ser]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGroupProcess_np:\n",
    "    def __init__(self, K=8, alpha=0.1, beta=0.1, n_iters=30):\n",
    "        '''\n",
    "        A MovieGroupProcess is a conceptual model introduced by Yin and Wang 2014 to\n",
    "        describe their Gibbs sampling algorithm for a Dirichlet Mixture Model for the\n",
    "        clustering short text documents.\n",
    "        Reference: http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n",
    "        Imagine a professor is leading a film class. At the start of the class, the students\n",
    "        are randomly assigned to K tables. Before class begins, the students make lists of\n",
    "        their favorite films. The teacher reads the role n_iters times. When\n",
    "        a student is called, the student must select a new table satisfying either:\n",
    "            1) The new table has more students than the current table.\n",
    "        OR\n",
    "            2) The new table has students with similar lists of favorite movies.\n",
    "        :param K: int\n",
    "            Upper bound on the number of possible clusters. Typically many fewer\n",
    "        :param alpha: float between 0 and 1\n",
    "            Alpha controls the probability that a student will join a table that is currently empty\n",
    "            When alpha is 0, no one will join an empty table.\n",
    "        :param beta: float between 0 and 1\n",
    "            Beta controls the student's affinity for other students with similar interests. A low beta means\n",
    "            that students desire to sit with students of similar interests. A high beta means they are less\n",
    "            concerned with affinity and are more influenced by the popularity of a table\n",
    "        :param n_iters:\n",
    "        '''\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.n_iters = n_iters\n",
    "\n",
    "        # slots for computed variables\n",
    "        self.number_docs = None\n",
    "        self.vocab_size = None\n",
    "        self.cluster_doc_count = np.repeat(0,K)\n",
    "        self.cluster_word_count = np.repeat(0,K)\n",
    "        self.cluster_word_distribution =None\n",
    "#         self.cluster_doc_count = [0 for _ in range(K)]\n",
    "#         self.cluster_word_count = [0 for _ in range(K)]\n",
    "#         self.cluster_word_distribution = [{} for i in range(K)]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_data(K, alpha, beta, D, vocab_size, cluster_doc_count, cluster_word_count, cluster_word_distribution):\n",
    "        '''\n",
    "        Reconstitute a MovieGroupProcess from previously fit data\n",
    "        :param K:\n",
    "        :param alpha:\n",
    "        :param beta:\n",
    "        :param D:\n",
    "        :param vocab_size:\n",
    "        :param cluster_doc_count:\n",
    "        :param cluster_word_count:\n",
    "        :param cluster_word_distribution:\n",
    "        :return:\n",
    "        '''\n",
    "        mgp = MovieGroupProcess(K, alpha, beta, n_iters=30)\n",
    "        mgp.number_docs = D\n",
    "        mgp.vocab_size = vocab_size\n",
    "        mgp.cluster_doc_count = cluster_doc_count\n",
    "        mgp.cluster_word_count = cluster_word_count\n",
    "        mgp.cluster_word_distribution = cluster_word_distribution\n",
    "        return mgp\n",
    "\n",
    "    @staticmethod\n",
    "    def _sample(p):\n",
    "        '''\n",
    "        Sample with probability vector p from a multinomial distribution\n",
    "        :param p: list\n",
    "            List of probabilities representing probability vector for the multinomial distribution\n",
    "        :return: int\n",
    "            index of randomly selected output\n",
    "        '''\n",
    "        #return np.where(multinomial(1,p)==1)[0][0]\n",
    "        return [i for i, entry in enumerate(multinomial(1, p)) if entry != 0][0]\n",
    "\n",
    "    def fit(self, docs, vocab_size):\n",
    "        '''\n",
    "        Cluster the input documents\n",
    "        :param docs: list of list\n",
    "            list of lists containing the unique token set of each document\n",
    "        :param V: total vocabulary size for each document\n",
    "        :return: list of length len(doc)\n",
    "            cluster label for each document\n",
    "        '''\n",
    "        alpha, beta, K, n_iters, V = self.alpha, self.beta, self.K, self.n_iters, vocab_size\n",
    "\n",
    "        D = len(docs)\n",
    "        self.number_docs = D\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # unpack to easy var names\n",
    "        self.cluster_word_distribution=np.zeros((K,vocab_size))\n",
    "        print(self.cluster_word_distribution.shape)\n",
    "        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n",
    "        cluster_count = K\n",
    "        d_z = np.repeat(0,D)\n",
    "\n",
    "        # initialize the clusters\n",
    "        for i, doc in enumerate(docs):\n",
    "\n",
    "            # choose a random  initial cluster for the doc\n",
    "            z = self._sample([1.0 / K for _ in range(K)])\n",
    "#             if sum(doc>0)==0:\n",
    "#                 continue\n",
    "            d_z[i] = z\n",
    "            m_z[z] += 1\n",
    "            n_z[z] += sum(doc)\n",
    "            n_z_w[z]+=doc\n",
    "#             for word in doc:\n",
    "#                 #print(word)\n",
    "#                 if word not in n_z_w[z]:\n",
    "#                     n_z_w[z][word] = 0\n",
    "#                 n_z_w[z][word] += 1\n",
    "        #print(n_z_w)\n",
    "        for _iter in range(n_iters):\n",
    "            total_transfers = 0\n",
    "\n",
    "            for i, doc in enumerate(docs):\n",
    "\n",
    "                # remove the doc from it's current cluster\n",
    "                z_old = d_z[i]\n",
    "#                 if sum(doc>0)==0:\n",
    "#                     continue\n",
    "                m_z[z_old] -= 1\n",
    "                n_z[z_old] -= sum(doc)\n",
    "                n_z_w[z_old]-=doc\n",
    "#                 for word in doc:\n",
    "#                     n_z_w[z_old][word] -= 1\n",
    "\n",
    "#                     # compact dictionary to save space\n",
    "#                     if n_z_w[z_old][word] == 0:\n",
    "#                         del n_z_w[z_old][word]\n",
    "\n",
    "                # draw sample from distribution to find new cluster\n",
    "                p = self.score(doc)\n",
    "                z_new = self._sample(p)\n",
    "                #print(z_new)\n",
    "                # transfer doc to the new cluster\n",
    "                if z_new != z_old:\n",
    "                    total_transfers += 1\n",
    "\n",
    "                d_z[i] = z_new\n",
    "                m_z[z_new] += 1\n",
    "                n_z[z_new] += sum(doc)\n",
    "                n_z_w[z_new]+=doc\n",
    "#                 for word in doc:\n",
    "#                     if word not in n_z_w[z_new]:\n",
    "#                         n_z_w[z_new][word] = 0\n",
    "#                     n_z_w[z_new][word] += 1\n",
    "\n",
    "            cluster_count_new = sum([1 for v in m_z if v > 0])\n",
    "            print(\"In stage %d: transferred %d clusters with %d clusters populated\" % (\n",
    "            _iter, total_transfers, cluster_count_new))\n",
    "            if total_transfers == 0 and cluster_count_new == cluster_count and _iter>25:\n",
    "                print(\"Converged.  Breaking out.\")\n",
    "                break\n",
    "            self.cluster_count = cluster_count_new\n",
    "        self.cluster_word_distribution = n_z_w\n",
    "        return d_z\n",
    "\n",
    "    def score(self, doc):\n",
    "        '''\n",
    "        Score a document\n",
    "        Implements formula (3) of Yin and Wang 2014.\n",
    "        http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n",
    "        :param doc: list[str]: The doc token stream\n",
    "        :return: list[float]: A length K probability vector where each component represents\n",
    "                              the probability of the document appearing in a particular cluster\n",
    "        '''\n",
    "        alpha, beta, K, V, D = self.alpha, self.beta, self.K, self.vocab_size, self.number_docs\n",
    "        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n",
    "\n",
    "        #p = np.repeat(0,K)\n",
    "\n",
    "        #  We break the formula into the following pieces\n",
    "        #  p = N1*N2/(D1*D2) = exp(lN1 - lD1 + lN2 - lD2)\n",
    "        #  lN1 = log(m_z[z] + alpha)\n",
    "        #  lN2 = log(D - 1 + K*alpha)\n",
    "        #  lN2 = log(product(n_z_w[w] + beta)) = sum(log(n_z_w[w] + beta))\n",
    "        #  lD2 = log(product(n_z[d] + V*beta + i -1)) = sum(log(n_z[d] + V*beta + i -1))\n",
    "\n",
    "        lD1 = log(D - 1 + K * alpha)\n",
    "        doc_size = sum(doc)\n",
    "        #print(doc_size)\n",
    "        #print(sum(doc),sum(doc>0))\n",
    "        lN2=np.dot(np.log(n_z_w+beta),doc).T[0]\n",
    "        #lN2=doc[doc>0]*np.log(n_z_w[doc>0]+beta)\n",
    "        \n",
    "        #print([[np.log(n_z[i]+V * beta + j - 1) for j in range(1, doc_size +1)] for i in range(K)])\n",
    "        #print(n_z)\n",
    "        lD2=np.array([np.sum([np.log(n_z[i]+V * beta + j - 1) for j in range(1, doc_size +1)]) for i in range(K)])\n",
    "        lN1=np.log(m_z+alpha)\n",
    "        #print(lD2)\n",
    "        p=np.exp(lN1 - lD1 + lN2 - lD2)\n",
    "#         for label in range(K):\n",
    "#             lN1 = log(m_z[label] + alpha)\n",
    "#             lN2 = 0\n",
    "#             lD2 = 0\n",
    "#             for word in doc:\n",
    "#                 lN2 += log(n_z_w[label].get(word, 0) + beta)\n",
    "#             for j in range(1, doc_size +1):\n",
    "#                 lD2 += log(n_z[label] + V * beta + j - 1)\n",
    "#             p[label] = exp(lN1 - lD1 + lN2 - lD2)\n",
    "\n",
    "        # normalize the probability vector\n",
    "        #print(lN1,lD1 , lN2 , lD2)\n",
    "        #print(p)\n",
    "        pnorm = sum(p)\n",
    "        pnorm = pnorm if pnorm>0 else 1\n",
    "        #return [pp/pnorm for pp in p]\n",
    "        return p/pnorm\n",
    "    \n",
    "    def choose_best_label(self, doc):\n",
    "        '''\n",
    "        Choose the highest probability label for the input document\n",
    "        :param doc: list[str]: The doc token stream\n",
    "        :return:\n",
    "        '''\n",
    "        p = self.score(doc)\n",
    "        return argmax(p),max(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "word_size=len(set(reduce(lambda x,y:list(x)+list(y),processed_docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_docs=[csr_matrix((a[1],(np.repeat(0,len(a[0])),a[0]))).toarray().flatten()   for a in [list(zip(*dictionary.doc2bow(doc))) for doc in processed_docs] if len(a)>0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MovieGroupProcess_np(K=10, alpha=0.1, beta=0.01, n_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_docs=[csr_matrix((a[1],(np.repeat(0,len(a[0])),a[0])),shape=(1,word_size)).toarray().flatten()  for a in [list(zip(*dictionary.doc2bow(doc))) for doc in processed_docs] if len(a)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2772)\n",
      "In stage 0: transferred 198 clusters with 10 clusters populated\n",
      "In stage 1: transferred 75 clusters with 10 clusters populated\n",
      "In stage 2: transferred 74 clusters with 10 clusters populated\n",
      "In stage 3: transferred 80 clusters with 10 clusters populated\n",
      "In stage 4: transferred 81 clusters with 10 clusters populated\n",
      "In stage 5: transferred 77 clusters with 10 clusters populated\n",
      "In stage 6: transferred 76 clusters with 10 clusters populated\n",
      "In stage 7: transferred 83 clusters with 10 clusters populated\n",
      "In stage 8: transferred 87 clusters with 10 clusters populated\n",
      "In stage 9: transferred 89 clusters with 10 clusters populated\n",
      "In stage 10: transferred 87 clusters with 10 clusters populated\n",
      "In stage 11: transferred 84 clusters with 10 clusters populated\n",
      "In stage 12: transferred 89 clusters with 10 clusters populated\n",
      "In stage 13: transferred 86 clusters with 10 clusters populated\n",
      "In stage 14: transferred 86 clusters with 10 clusters populated\n",
      "In stage 15: transferred 85 clusters with 10 clusters populated\n",
      "In stage 16: transferred 86 clusters with 10 clusters populated\n",
      "In stage 17: transferred 93 clusters with 10 clusters populated\n",
      "In stage 18: transferred 87 clusters with 10 clusters populated\n",
      "In stage 19: transferred 81 clusters with 10 clusters populated\n",
      "In stage 20: transferred 88 clusters with 10 clusters populated\n",
      "In stage 21: transferred 86 clusters with 10 clusters populated\n",
      "In stage 22: transferred 84 clusters with 10 clusters populated\n",
      "In stage 23: transferred 79 clusters with 10 clusters populated\n",
      "In stage 24: transferred 82 clusters with 10 clusters populated\n",
      "In stage 25: transferred 81 clusters with 10 clusters populated\n",
      "In stage 26: transferred 79 clusters with 10 clusters populated\n",
      "In stage 27: transferred 84 clusters with 10 clusters populated\n",
      "In stage 28: transferred 89 clusters with 10 clusters populated\n",
      "In stage 29: transferred 79 clusters with 10 clusters populated\n",
      "In stage 30: transferred 74 clusters with 10 clusters populated\n",
      "In stage 31: transferred 77 clusters with 10 clusters populated\n",
      "In stage 32: transferred 76 clusters with 10 clusters populated\n",
      "In stage 33: transferred 84 clusters with 10 clusters populated\n",
      "In stage 34: transferred 87 clusters with 10 clusters populated\n",
      "In stage 35: transferred 92 clusters with 10 clusters populated\n",
      "In stage 36: transferred 82 clusters with 10 clusters populated\n",
      "In stage 37: transferred 86 clusters with 10 clusters populated\n",
      "In stage 38: transferred 84 clusters with 10 clusters populated\n",
      "In stage 39: transferred 86 clusters with 10 clusters populated\n",
      "In stage 40: transferred 83 clusters with 10 clusters populated\n",
      "In stage 41: transferred 88 clusters with 10 clusters populated\n",
      "In stage 42: transferred 79 clusters with 10 clusters populated\n",
      "In stage 43: transferred 85 clusters with 10 clusters populated\n",
      "In stage 44: transferred 81 clusters with 10 clusters populated\n",
      "In stage 45: transferred 80 clusters with 10 clusters populated\n",
      "In stage 46: transferred 85 clusters with 10 clusters populated\n",
      "In stage 47: transferred 82 clusters with 10 clusters populated\n",
      "In stage 48: transferred 89 clusters with 10 clusters populated\n",
      "In stage 49: transferred 81 clusters with 10 clusters populated\n",
      "In stage 50: transferred 86 clusters with 10 clusters populated\n",
      "In stage 51: transferred 88 clusters with 10 clusters populated\n",
      "In stage 52: transferred 78 clusters with 10 clusters populated\n",
      "In stage 53: transferred 74 clusters with 10 clusters populated\n",
      "In stage 54: transferred 78 clusters with 10 clusters populated\n",
      "In stage 55: transferred 84 clusters with 10 clusters populated\n",
      "In stage 56: transferred 80 clusters with 10 clusters populated\n",
      "In stage 57: transferred 87 clusters with 10 clusters populated\n",
      "In stage 58: transferred 77 clusters with 10 clusters populated\n",
      "In stage 59: transferred 78 clusters with 10 clusters populated\n",
      "In stage 60: transferred 81 clusters with 10 clusters populated\n",
      "In stage 61: transferred 85 clusters with 10 clusters populated\n",
      "In stage 62: transferred 86 clusters with 10 clusters populated\n",
      "In stage 63: transferred 91 clusters with 10 clusters populated\n",
      "In stage 64: transferred 91 clusters with 10 clusters populated\n",
      "In stage 65: transferred 88 clusters with 10 clusters populated\n",
      "In stage 66: transferred 85 clusters with 10 clusters populated\n",
      "In stage 67: transferred 88 clusters with 10 clusters populated\n",
      "In stage 68: transferred 79 clusters with 10 clusters populated\n",
      "In stage 69: transferred 97 clusters with 10 clusters populated\n",
      "In stage 70: transferred 91 clusters with 10 clusters populated\n",
      "In stage 71: transferred 76 clusters with 10 clusters populated\n",
      "In stage 72: transferred 85 clusters with 10 clusters populated\n",
      "In stage 73: transferred 77 clusters with 10 clusters populated\n",
      "In stage 74: transferred 71 clusters with 10 clusters populated\n",
      "In stage 75: transferred 73 clusters with 10 clusters populated\n",
      "In stage 76: transferred 88 clusters with 10 clusters populated\n",
      "In stage 77: transferred 85 clusters with 10 clusters populated\n",
      "In stage 78: transferred 75 clusters with 10 clusters populated\n",
      "In stage 79: transferred 88 clusters with 10 clusters populated\n",
      "In stage 80: transferred 83 clusters with 10 clusters populated\n",
      "In stage 81: transferred 88 clusters with 10 clusters populated\n",
      "In stage 82: transferred 82 clusters with 10 clusters populated\n",
      "In stage 83: transferred 90 clusters with 10 clusters populated\n",
      "In stage 84: transferred 86 clusters with 10 clusters populated\n",
      "In stage 85: transferred 80 clusters with 10 clusters populated\n",
      "In stage 86: transferred 86 clusters with 10 clusters populated\n",
      "In stage 87: transferred 80 clusters with 10 clusters populated\n",
      "In stage 88: transferred 78 clusters with 10 clusters populated\n",
      "In stage 89: transferred 86 clusters with 10 clusters populated\n",
      "In stage 90: transferred 89 clusters with 10 clusters populated\n",
      "In stage 91: transferred 85 clusters with 10 clusters populated\n",
      "In stage 92: transferred 85 clusters with 10 clusters populated\n",
      "In stage 93: transferred 90 clusters with 10 clusters populated\n",
      "In stage 94: transferred 88 clusters with 10 clusters populated\n",
      "In stage 95: transferred 83 clusters with 10 clusters populated\n",
      "In stage 96: transferred 80 clusters with 10 clusters populated\n",
      "In stage 97: transferred 95 clusters with 10 clusters populated\n",
      "In stage 98: transferred 85 clusters with 10 clusters populated\n",
      "In stage 99: transferred 78 clusters with 10 clusters populated\n",
      "In stage 100: transferred 84 clusters with 10 clusters populated\n",
      "In stage 101: transferred 87 clusters with 10 clusters populated\n",
      "In stage 102: transferred 87 clusters with 10 clusters populated\n",
      "In stage 103: transferred 76 clusters with 10 clusters populated\n",
      "In stage 104: transferred 99 clusters with 10 clusters populated\n",
      "In stage 105: transferred 89 clusters with 10 clusters populated\n",
      "In stage 106: transferred 89 clusters with 10 clusters populated\n",
      "In stage 107: transferred 85 clusters with 10 clusters populated\n",
      "In stage 108: transferred 87 clusters with 10 clusters populated\n",
      "In stage 109: transferred 84 clusters with 10 clusters populated\n",
      "In stage 110: transferred 81 clusters with 10 clusters populated\n",
      "In stage 111: transferred 80 clusters with 10 clusters populated\n",
      "In stage 112: transferred 71 clusters with 10 clusters populated\n",
      "In stage 113: transferred 87 clusters with 10 clusters populated\n",
      "In stage 114: transferred 94 clusters with 10 clusters populated\n",
      "In stage 115: transferred 86 clusters with 10 clusters populated\n",
      "In stage 116: transferred 93 clusters with 10 clusters populated\n",
      "In stage 117: transferred 91 clusters with 10 clusters populated\n",
      "In stage 118: transferred 77 clusters with 10 clusters populated\n",
      "In stage 119: transferred 91 clusters with 10 clusters populated\n",
      "In stage 120: transferred 86 clusters with 10 clusters populated\n",
      "In stage 121: transferred 89 clusters with 10 clusters populated\n",
      "In stage 122: transferred 79 clusters with 10 clusters populated\n",
      "In stage 123: transferred 83 clusters with 10 clusters populated\n",
      "In stage 124: transferred 94 clusters with 10 clusters populated\n",
      "In stage 125: transferred 83 clusters with 10 clusters populated\n",
      "In stage 126: transferred 90 clusters with 10 clusters populated\n",
      "In stage 127: transferred 74 clusters with 10 clusters populated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 128: transferred 89 clusters with 10 clusters populated\n",
      "In stage 129: transferred 90 clusters with 10 clusters populated\n",
      "In stage 130: transferred 84 clusters with 10 clusters populated\n",
      "In stage 131: transferred 83 clusters with 10 clusters populated\n",
      "In stage 132: transferred 82 clusters with 10 clusters populated\n",
      "In stage 133: transferred 83 clusters with 10 clusters populated\n",
      "In stage 134: transferred 82 clusters with 10 clusters populated\n",
      "In stage 135: transferred 84 clusters with 10 clusters populated\n",
      "In stage 136: transferred 80 clusters with 10 clusters populated\n",
      "In stage 137: transferred 87 clusters with 10 clusters populated\n",
      "In stage 138: transferred 91 clusters with 10 clusters populated\n",
      "In stage 139: transferred 84 clusters with 10 clusters populated\n",
      "In stage 140: transferred 81 clusters with 10 clusters populated\n",
      "In stage 141: transferred 79 clusters with 10 clusters populated\n",
      "In stage 142: transferred 84 clusters with 10 clusters populated\n",
      "In stage 143: transferred 80 clusters with 10 clusters populated\n",
      "In stage 144: transferred 88 clusters with 10 clusters populated\n",
      "In stage 145: transferred 77 clusters with 10 clusters populated\n",
      "In stage 146: transferred 94 clusters with 10 clusters populated\n",
      "In stage 147: transferred 82 clusters with 10 clusters populated\n",
      "In stage 148: transferred 95 clusters with 10 clusters populated\n",
      "In stage 149: transferred 93 clusters with 10 clusters populated\n",
      "In stage 150: transferred 83 clusters with 10 clusters populated\n",
      "In stage 151: transferred 78 clusters with 10 clusters populated\n",
      "In stage 152: transferred 86 clusters with 10 clusters populated\n",
      "In stage 153: transferred 86 clusters with 10 clusters populated\n",
      "In stage 154: transferred 79 clusters with 10 clusters populated\n",
      "In stage 155: transferred 92 clusters with 10 clusters populated\n",
      "In stage 156: transferred 85 clusters with 10 clusters populated\n",
      "In stage 157: transferred 80 clusters with 10 clusters populated\n",
      "In stage 158: transferred 92 clusters with 10 clusters populated\n",
      "In stage 159: transferred 77 clusters with 10 clusters populated\n",
      "In stage 160: transferred 91 clusters with 10 clusters populated\n",
      "In stage 161: transferred 103 clusters with 10 clusters populated\n",
      "In stage 162: transferred 87 clusters with 10 clusters populated\n",
      "In stage 163: transferred 87 clusters with 10 clusters populated\n",
      "In stage 164: transferred 85 clusters with 10 clusters populated\n",
      "In stage 165: transferred 87 clusters with 10 clusters populated\n",
      "In stage 166: transferred 89 clusters with 10 clusters populated\n",
      "In stage 167: transferred 84 clusters with 10 clusters populated\n",
      "In stage 168: transferred 86 clusters with 10 clusters populated\n",
      "In stage 169: transferred 87 clusters with 10 clusters populated\n",
      "In stage 170: transferred 81 clusters with 10 clusters populated\n",
      "In stage 171: transferred 90 clusters with 10 clusters populated\n",
      "In stage 172: transferred 86 clusters with 10 clusters populated\n",
      "In stage 173: transferred 82 clusters with 10 clusters populated\n",
      "In stage 174: transferred 81 clusters with 10 clusters populated\n",
      "In stage 175: transferred 82 clusters with 10 clusters populated\n",
      "In stage 176: transferred 87 clusters with 10 clusters populated\n",
      "In stage 177: transferred 84 clusters with 10 clusters populated\n",
      "In stage 178: transferred 78 clusters with 10 clusters populated\n",
      "In stage 179: transferred 86 clusters with 10 clusters populated\n",
      "In stage 180: transferred 69 clusters with 10 clusters populated\n",
      "In stage 181: transferred 85 clusters with 10 clusters populated\n",
      "In stage 182: transferred 82 clusters with 10 clusters populated\n",
      "In stage 183: transferred 95 clusters with 10 clusters populated\n",
      "In stage 184: transferred 85 clusters with 10 clusters populated\n",
      "In stage 185: transferred 81 clusters with 10 clusters populated\n",
      "In stage 186: transferred 85 clusters with 10 clusters populated\n",
      "In stage 187: transferred 86 clusters with 10 clusters populated\n",
      "In stage 188: transferred 75 clusters with 10 clusters populated\n",
      "In stage 189: transferred 87 clusters with 10 clusters populated\n",
      "In stage 190: transferred 81 clusters with 10 clusters populated\n",
      "In stage 191: transferred 86 clusters with 10 clusters populated\n",
      "In stage 192: transferred 79 clusters with 10 clusters populated\n",
      "In stage 193: transferred 78 clusters with 10 clusters populated\n",
      "In stage 194: transferred 85 clusters with 10 clusters populated\n",
      "In stage 195: transferred 80 clusters with 10 clusters populated\n",
      "In stage 196: transferred 86 clusters with 10 clusters populated\n",
      "In stage 197: transferred 77 clusters with 10 clusters populated\n",
      "In stage 198: transferred 96 clusters with 10 clusters populated\n",
      "In stage 199: transferred 86 clusters with 10 clusters populated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 1, 6, 9, 1, 0, 2, 1, 9, 7, 5, 9, 2, 5, 9, 0, 3, 9, 2, 9, 9, 5,\n",
       "       9, 8, 9, 5, 9, 9, 9, 4, 8, 4, 3, 9, 5, 4, 9, 4, 9, 0, 5, 9, 9, 9,\n",
       "       8, 9, 9, 8, 9, 3, 6, 9, 9, 9, 7, 8, 9, 8, 9, 8, 2, 9, 9, 6, 7, 9,\n",
       "       9, 9, 9, 6, 9, 9, 9, 9, 2, 9, 2, 9, 4, 9, 2, 3, 9, 9, 8, 9, 7, 3,\n",
       "       9, 9, 4, 9, 6, 3, 9, 3, 4, 9, 4, 9, 6, 2, 1, 7, 9, 0, 6, 9, 9, 6,\n",
       "       9, 1, 9, 5, 9, 4, 4, 9, 6, 2, 9, 2, 6, 9, 3, 9, 0, 5, 7, 6, 9, 8,\n",
       "       0, 1, 3, 9, 0, 6, 9, 9, 8, 9, 6, 6, 9, 5, 9, 9, 4, 8, 2, 1, 9, 4,\n",
       "       6, 0, 6, 9, 6, 4, 5, 3, 0, 2, 4, 8, 6, 4, 0, 8, 3, 9, 7, 9, 8, 9,\n",
       "       4, 1, 9, 8, 9, 7, 0, 2, 6, 9, 5, 9, 6, 9, 8, 9, 0, 9, 3, 9, 9, 2,\n",
       "       9, 9, 9, 3, 7, 9, 8, 9, 5, 0, 9, 8, 9, 7, 1, 9, 3, 6, 6, 1, 1, 9,\n",
       "       2, 9, 8, 9, 4, 4, 7, 9, 8])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(vec_docs,word_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGroupProcess_py:\n",
    "    def __init__(self, K=8, alpha=0.1, beta=0.1, n_iters=30):\n",
    "        '''\n",
    "        A MovieGroupProcess is a conceptual model introduced by Yin and Wang 2014 to\n",
    "        describe their Gibbs sampling algorithm for a Dirichlet Mixture Model for the\n",
    "        clustering short text documents.\n",
    "        Reference: http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n",
    "        Imagine a professor is leading a film class. At the start of the class, the students\n",
    "        are randomly assigned to K tables. Before class begins, the students make lists of\n",
    "        their favorite films. The teacher reads the role n_iters times. When\n",
    "        a student is called, the student must select a new table satisfying either:\n",
    "            1) The new table has more students than the current table.\n",
    "        OR\n",
    "            2) The new table has students with similar lists of favorite movies.\n",
    "        :param K: int\n",
    "            Upper bound on the number of possible clusters. Typically many fewer\n",
    "        :param alpha: float between 0 and 1\n",
    "            Alpha controls the probability that a student will join a table that is currently empty\n",
    "            When alpha is 0, no one will join an empty table.\n",
    "        :param beta: float between 0 and 1\n",
    "            Beta controls the student's affinity for other students with similar interests. A low beta means\n",
    "            that students desire to sit with students of similar interests. A high beta means they are less\n",
    "            concerned with affinity and are more influenced by the popularity of a table\n",
    "        :param n_iters:\n",
    "        '''\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.n_iters = n_iters\n",
    "\n",
    "        # slots for computed variables\n",
    "        self.number_docs = None\n",
    "        self.vocab_size = None\n",
    "        self.cluster_doc_count = np.repeat(0,K)\n",
    "        self.cluster_word_count = np.repeat(0,K)\n",
    "        self.cluster_word_distribution = [{} for i in range(K)]\n",
    "\n",
    "    @staticmethod\n",
    "    def from_data(K, alpha, beta, D, vocab_size, cluster_doc_count, cluster_word_count, cluster_word_distribution):\n",
    "        '''\n",
    "        Reconstitute a MovieGroupProcess from previously fit data\n",
    "        :param K:\n",
    "        :param alpha:\n",
    "        :param beta:\n",
    "        :param D:\n",
    "        :param vocab_size:\n",
    "        :param cluster_doc_count:\n",
    "        :param cluster_word_count:\n",
    "        :param cluster_word_distribution:\n",
    "        :return:\n",
    "        '''\n",
    "        mgp = MovieGroupProcess(K, alpha, beta, n_iters=30)\n",
    "        mgp.number_docs = D\n",
    "        mgp.vocab_size = vocab_size\n",
    "        mgp.cluster_doc_count = cluster_doc_count\n",
    "        mgp.cluster_word_count = cluster_word_count\n",
    "        mgp.cluster_word_distribution = cluster_word_distribution\n",
    "        return mgp\n",
    "\n",
    "    @staticmethod\n",
    "    def _sample(p):\n",
    "        '''\n",
    "        Sample with probability vector p from a multinomial distribution\n",
    "        :param p: list\n",
    "            List of probabilities representing probability vector for the multinomial distribution\n",
    "        :return: int\n",
    "            index of randomly selected output\n",
    "        '''\n",
    "        return [i for i, entry in enumerate(multinomial(1, p)) if entry != 0][0]\n",
    "\n",
    "    def fit(self, docs, vocab_size):\n",
    "        '''\n",
    "        Cluster the input documents\n",
    "        :param docs: list of list\n",
    "            list of lists containing the unique token set of each document\n",
    "        :param V: total vocabulary size for each document\n",
    "        :return: list of length len(doc)\n",
    "            cluster label for each document\n",
    "        '''\n",
    "        alpha, beta, K, n_iters, V = self.alpha, self.beta, self.K, self.n_iters, vocab_size\n",
    "\n",
    "        D = len(docs)\n",
    "        self.number_docs = D\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        # unpack to easy var names\n",
    "        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n",
    "        cluster_count = K\n",
    "        d_z = [None for i in range(len(docs))]\n",
    "\n",
    "        # initialize the clusters\n",
    "        for i, doc in enumerate(docs):\n",
    "\n",
    "            # choose a random  initial cluster for the doc\n",
    "            z = self._sample([1.0 / K for _ in range(K)])\n",
    "            d_z[i] = z\n",
    "            m_z[z] += 1\n",
    "            n_z[z] += len(doc)\n",
    "\n",
    "            for word in doc:\n",
    "                #print(word)\n",
    "                if word not in n_z_w[z]:\n",
    "                    n_z_w[z][word] = 0\n",
    "                n_z_w[z][word] += 1\n",
    "        #print(n_z_w)\n",
    "        for _iter in range(n_iters):\n",
    "            total_transfers = 0\n",
    "\n",
    "            for i, doc in enumerate(docs):\n",
    "\n",
    "                # remove the doc from it's current cluster\n",
    "                z_old = d_z[i]\n",
    "\n",
    "                m_z[z_old] -= 1\n",
    "                n_z[z_old] -= len(doc)\n",
    "\n",
    "                for word in doc:\n",
    "                    n_z_w[z_old][word] -= 1\n",
    "\n",
    "                    # compact dictionary to save space\n",
    "                    if n_z_w[z_old][word] == 0:\n",
    "                        del n_z_w[z_old][word]\n",
    "\n",
    "                # draw sample from distribution to find new cluster\n",
    "                p = self.score(doc)\n",
    "                z_new = self._sample(p)\n",
    "\n",
    "                # transfer doc to the new cluster\n",
    "                if z_new != z_old:\n",
    "                    total_transfers += 1\n",
    "\n",
    "                d_z[i] = z_new\n",
    "                m_z[z_new] += 1\n",
    "                n_z[z_new] += len(doc)\n",
    "\n",
    "                for word in doc:\n",
    "                    if word not in n_z_w[z_new]:\n",
    "                        n_z_w[z_new][word] = 0\n",
    "                    n_z_w[z_new][word] += 1\n",
    "\n",
    "            cluster_count_new = sum([1 for v in m_z if v > 0])\n",
    "            print(\"In stage %d: transferred %d clusters with %d clusters populated\" % (\n",
    "            _iter, total_transfers, cluster_count_new))\n",
    "            if total_transfers == 0 and cluster_count_new == cluster_count and _iter>25:\n",
    "                print(\"Converged.  Breaking out.\")\n",
    "                break\n",
    "            self.cluster_count = cluster_count_new\n",
    "        self.cluster_word_distribution = n_z_w\n",
    "        return d_z\n",
    "\n",
    "    def score(self, doc):\n",
    "        '''\n",
    "        Score a document\n",
    "        Implements formula (3) of Yin and Wang 2014.\n",
    "        http://dbgroup.cs.tsinghua.edu.cn/wangjy/papers/KDD14-GSDMM.pdf\n",
    "        :param doc: list[str]: The doc token stream\n",
    "        :return: list[float]: A length K probability vector where each component represents\n",
    "                              the probability of the document appearing in a particular cluster\n",
    "        '''\n",
    "        alpha, beta, K, V, D = self.alpha, self.beta, self.K, self.vocab_size, self.number_docs\n",
    "        m_z, n_z, n_z_w = self.cluster_doc_count, self.cluster_word_count, self.cluster_word_distribution\n",
    "\n",
    "        p = [0 for _ in range(K)]\n",
    "\n",
    "        #  We break the formula into the following pieces\n",
    "        #  p = N1*N2/(D1*D2) = exp(lN1 - lD1 + lN2 - lD2)\n",
    "        #  lN1 = log(m_z[z] + alpha)\n",
    "        #  lN2 = log(D - 1 + K*alpha)\n",
    "        #  lN2 = log(product(n_z_w[w] + beta)) = sum(log(n_z_w[w] + beta))\n",
    "        #  lD2 = log(product(n_z[d] + V*beta + i -1)) = sum(log(n_z[d] + V*beta + i -1))\n",
    "        \n",
    "        lD1 = log(D - 1 + K * alpha)\n",
    "        doc_size = len(doc)\n",
    "        #print(doc_size)\n",
    "        p=[exp(log(m_z[label] + alpha)-lD1+sum([log(n_z_w[label].get(word, 0) + beta) for word in doc])-sum([log(n_z[label] + V * beta + j - 1) for j in range(1, doc_size +1)])) for label in range(K)]\n",
    "#         for label in range(K):\n",
    "#             lN1 = log(m_z[label] + alpha)\n",
    "#             lN2 = 0\n",
    "#             lD2 = 0\n",
    "#             for word in doc:\n",
    "#                 lN2 += log(n_z_w[label].get(word, 0) + beta)\n",
    "#             for j in range(1, doc_size +1):\n",
    "#                 lD2 += log(n_z[label] + V * beta + j - 1)\n",
    "#             #print(lD2)\n",
    "#             p[label] = exp(lN1 - lD1 + lN2 - lD2)\n",
    "\n",
    "        # normalize the probability vector\n",
    "        #print(p)\n",
    "        pnorm = sum(p)\n",
    "        pnorm = pnorm if pnorm>0 else 1\n",
    "        return [pp/pnorm for pp in p]\n",
    "\n",
    "    def choose_best_label(self, doc):\n",
    "        '''\n",
    "        Choose the highest probability label for the input document\n",
    "        :param doc: list[str]: The doc token stream\n",
    "        :return:\n",
    "        '''\n",
    "        p = self.score(doc)\n",
    "        return argmax(p),max(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MovieGroupProcess_py(K=10, alpha=0.1, beta=0.01, n_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 237 clusters with 10 clusters populated\n",
      "In stage 1: transferred 19 clusters with 10 clusters populated\n",
      "In stage 2: transferred 19 clusters with 10 clusters populated\n",
      "In stage 3: transferred 17 clusters with 10 clusters populated\n",
      "In stage 4: transferred 12 clusters with 10 clusters populated\n",
      "In stage 5: transferred 7 clusters with 10 clusters populated\n",
      "In stage 6: transferred 7 clusters with 10 clusters populated\n",
      "In stage 7: transferred 7 clusters with 10 clusters populated\n",
      "In stage 8: transferred 10 clusters with 10 clusters populated\n",
      "In stage 9: transferred 15 clusters with 10 clusters populated\n",
      "In stage 10: transferred 11 clusters with 10 clusters populated\n",
      "In stage 11: transferred 11 clusters with 10 clusters populated\n",
      "In stage 12: transferred 14 clusters with 10 clusters populated\n",
      "In stage 13: transferred 16 clusters with 10 clusters populated\n",
      "In stage 14: transferred 15 clusters with 10 clusters populated\n",
      "In stage 15: transferred 14 clusters with 10 clusters populated\n",
      "In stage 16: transferred 13 clusters with 10 clusters populated\n",
      "In stage 17: transferred 8 clusters with 10 clusters populated\n",
      "In stage 18: transferred 7 clusters with 10 clusters populated\n",
      "In stage 19: transferred 9 clusters with 10 clusters populated\n",
      "In stage 20: transferred 10 clusters with 10 clusters populated\n",
      "In stage 21: transferred 11 clusters with 10 clusters populated\n",
      "In stage 22: transferred 14 clusters with 10 clusters populated\n",
      "In stage 23: transferred 14 clusters with 10 clusters populated\n",
      "In stage 24: transferred 14 clusters with 10 clusters populated\n",
      "In stage 25: transferred 18 clusters with 10 clusters populated\n",
      "In stage 26: transferred 17 clusters with 10 clusters populated\n",
      "In stage 27: transferred 17 clusters with 10 clusters populated\n",
      "In stage 28: transferred 15 clusters with 10 clusters populated\n",
      "In stage 29: transferred 22 clusters with 10 clusters populated\n",
      "In stage 30: transferred 21 clusters with 10 clusters populated\n",
      "In stage 31: transferred 15 clusters with 10 clusters populated\n",
      "In stage 32: transferred 13 clusters with 10 clusters populated\n",
      "In stage 33: transferred 13 clusters with 10 clusters populated\n",
      "In stage 34: transferred 9 clusters with 10 clusters populated\n",
      "In stage 35: transferred 13 clusters with 10 clusters populated\n",
      "In stage 36: transferred 10 clusters with 10 clusters populated\n",
      "In stage 37: transferred 9 clusters with 10 clusters populated\n",
      "In stage 38: transferred 12 clusters with 10 clusters populated\n",
      "In stage 39: transferred 15 clusters with 10 clusters populated\n",
      "In stage 40: transferred 15 clusters with 10 clusters populated\n",
      "In stage 41: transferred 10 clusters with 10 clusters populated\n",
      "In stage 42: transferred 12 clusters with 10 clusters populated\n",
      "In stage 43: transferred 11 clusters with 10 clusters populated\n",
      "In stage 44: transferred 8 clusters with 10 clusters populated\n",
      "In stage 45: transferred 7 clusters with 10 clusters populated\n",
      "In stage 46: transferred 9 clusters with 10 clusters populated\n",
      "In stage 47: transferred 12 clusters with 10 clusters populated\n",
      "In stage 48: transferred 18 clusters with 10 clusters populated\n",
      "In stage 49: transferred 14 clusters with 10 clusters populated\n",
      "In stage 50: transferred 11 clusters with 10 clusters populated\n",
      "In stage 51: transferred 14 clusters with 10 clusters populated\n",
      "In stage 52: transferred 16 clusters with 10 clusters populated\n",
      "In stage 53: transferred 14 clusters with 10 clusters populated\n",
      "In stage 54: transferred 14 clusters with 10 clusters populated\n",
      "In stage 55: transferred 9 clusters with 10 clusters populated\n",
      "In stage 56: transferred 11 clusters with 10 clusters populated\n",
      "In stage 57: transferred 9 clusters with 10 clusters populated\n",
      "In stage 58: transferred 7 clusters with 10 clusters populated\n",
      "In stage 59: transferred 12 clusters with 10 clusters populated\n",
      "In stage 60: transferred 12 clusters with 10 clusters populated\n",
      "In stage 61: transferred 6 clusters with 10 clusters populated\n",
      "In stage 62: transferred 11 clusters with 10 clusters populated\n",
      "In stage 63: transferred 13 clusters with 10 clusters populated\n",
      "In stage 64: transferred 16 clusters with 10 clusters populated\n",
      "In stage 65: transferred 12 clusters with 10 clusters populated\n",
      "In stage 66: transferred 10 clusters with 10 clusters populated\n",
      "In stage 67: transferred 13 clusters with 10 clusters populated\n",
      "In stage 68: transferred 15 clusters with 10 clusters populated\n",
      "In stage 69: transferred 15 clusters with 10 clusters populated\n",
      "In stage 70: transferred 10 clusters with 10 clusters populated\n",
      "In stage 71: transferred 13 clusters with 10 clusters populated\n",
      "In stage 72: transferred 11 clusters with 10 clusters populated\n",
      "In stage 73: transferred 7 clusters with 10 clusters populated\n",
      "In stage 74: transferred 10 clusters with 10 clusters populated\n",
      "In stage 75: transferred 13 clusters with 10 clusters populated\n",
      "In stage 76: transferred 12 clusters with 10 clusters populated\n",
      "In stage 77: transferred 11 clusters with 10 clusters populated\n",
      "In stage 78: transferred 14 clusters with 10 clusters populated\n",
      "In stage 79: transferred 8 clusters with 10 clusters populated\n",
      "In stage 80: transferred 8 clusters with 10 clusters populated\n",
      "In stage 81: transferred 8 clusters with 10 clusters populated\n",
      "In stage 82: transferred 12 clusters with 10 clusters populated\n",
      "In stage 83: transferred 11 clusters with 10 clusters populated\n",
      "In stage 84: transferred 13 clusters with 10 clusters populated\n",
      "In stage 85: transferred 13 clusters with 10 clusters populated\n",
      "In stage 86: transferred 13 clusters with 10 clusters populated\n",
      "In stage 87: transferred 15 clusters with 10 clusters populated\n",
      "In stage 88: transferred 15 clusters with 10 clusters populated\n",
      "In stage 89: transferred 16 clusters with 10 clusters populated\n",
      "In stage 90: transferred 12 clusters with 10 clusters populated\n",
      "In stage 91: transferred 12 clusters with 10 clusters populated\n",
      "In stage 92: transferred 8 clusters with 10 clusters populated\n",
      "In stage 93: transferred 8 clusters with 10 clusters populated\n",
      "In stage 94: transferred 14 clusters with 10 clusters populated\n",
      "In stage 95: transferred 14 clusters with 10 clusters populated\n",
      "In stage 96: transferred 9 clusters with 10 clusters populated\n",
      "In stage 97: transferred 6 clusters with 10 clusters populated\n",
      "In stage 98: transferred 9 clusters with 10 clusters populated\n",
      "In stage 99: transferred 14 clusters with 10 clusters populated\n",
      "In stage 100: transferred 15 clusters with 10 clusters populated\n",
      "In stage 101: transferred 7 clusters with 10 clusters populated\n",
      "In stage 102: transferred 6 clusters with 10 clusters populated\n",
      "In stage 103: transferred 13 clusters with 10 clusters populated\n",
      "In stage 104: transferred 14 clusters with 10 clusters populated\n",
      "In stage 105: transferred 12 clusters with 10 clusters populated\n",
      "In stage 106: transferred 12 clusters with 10 clusters populated\n",
      "In stage 107: transferred 20 clusters with 10 clusters populated\n",
      "In stage 108: transferred 18 clusters with 10 clusters populated\n",
      "In stage 109: transferred 16 clusters with 10 clusters populated\n",
      "In stage 110: transferred 11 clusters with 10 clusters populated\n",
      "In stage 111: transferred 12 clusters with 10 clusters populated\n",
      "In stage 112: transferred 11 clusters with 10 clusters populated\n",
      "In stage 113: transferred 12 clusters with 10 clusters populated\n",
      "In stage 114: transferred 10 clusters with 10 clusters populated\n",
      "In stage 115: transferred 13 clusters with 10 clusters populated\n",
      "In stage 116: transferred 13 clusters with 10 clusters populated\n",
      "In stage 117: transferred 15 clusters with 10 clusters populated\n",
      "In stage 118: transferred 14 clusters with 10 clusters populated\n",
      "In stage 119: transferred 11 clusters with 10 clusters populated\n",
      "In stage 120: transferred 13 clusters with 10 clusters populated\n",
      "In stage 121: transferred 13 clusters with 10 clusters populated\n",
      "In stage 122: transferred 14 clusters with 10 clusters populated\n",
      "In stage 123: transferred 13 clusters with 10 clusters populated\n",
      "In stage 124: transferred 12 clusters with 10 clusters populated\n",
      "In stage 125: transferred 17 clusters with 10 clusters populated\n",
      "In stage 126: transferred 14 clusters with 10 clusters populated\n",
      "In stage 127: transferred 12 clusters with 10 clusters populated\n",
      "In stage 128: transferred 14 clusters with 10 clusters populated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 129: transferred 14 clusters with 10 clusters populated\n",
      "In stage 130: transferred 12 clusters with 10 clusters populated\n",
      "In stage 131: transferred 15 clusters with 10 clusters populated\n",
      "In stage 132: transferred 15 clusters with 10 clusters populated\n",
      "In stage 133: transferred 15 clusters with 10 clusters populated\n",
      "In stage 134: transferred 19 clusters with 10 clusters populated\n",
      "In stage 135: transferred 16 clusters with 10 clusters populated\n",
      "In stage 136: transferred 12 clusters with 10 clusters populated\n",
      "In stage 137: transferred 11 clusters with 10 clusters populated\n",
      "In stage 138: transferred 10 clusters with 10 clusters populated\n",
      "In stage 139: transferred 11 clusters with 10 clusters populated\n",
      "In stage 140: transferred 11 clusters with 10 clusters populated\n",
      "In stage 141: transferred 7 clusters with 10 clusters populated\n",
      "In stage 142: transferred 10 clusters with 10 clusters populated\n",
      "In stage 143: transferred 8 clusters with 10 clusters populated\n",
      "In stage 144: transferred 9 clusters with 10 clusters populated\n",
      "In stage 145: transferred 17 clusters with 10 clusters populated\n",
      "In stage 146: transferred 15 clusters with 10 clusters populated\n",
      "In stage 147: transferred 13 clusters with 10 clusters populated\n",
      "In stage 148: transferred 14 clusters with 10 clusters populated\n",
      "In stage 149: transferred 14 clusters with 10 clusters populated\n",
      "In stage 150: transferred 13 clusters with 10 clusters populated\n",
      "In stage 151: transferred 9 clusters with 10 clusters populated\n",
      "In stage 152: transferred 11 clusters with 10 clusters populated\n",
      "In stage 153: transferred 15 clusters with 10 clusters populated\n",
      "In stage 154: transferred 17 clusters with 10 clusters populated\n",
      "In stage 155: transferred 16 clusters with 10 clusters populated\n",
      "In stage 156: transferred 14 clusters with 10 clusters populated\n",
      "In stage 157: transferred 12 clusters with 10 clusters populated\n",
      "In stage 158: transferred 11 clusters with 10 clusters populated\n",
      "In stage 159: transferred 9 clusters with 10 clusters populated\n",
      "In stage 160: transferred 12 clusters with 10 clusters populated\n",
      "In stage 161: transferred 13 clusters with 10 clusters populated\n",
      "In stage 162: transferred 12 clusters with 10 clusters populated\n",
      "In stage 163: transferred 12 clusters with 10 clusters populated\n",
      "In stage 164: transferred 11 clusters with 10 clusters populated\n",
      "In stage 165: transferred 16 clusters with 10 clusters populated\n",
      "In stage 166: transferred 11 clusters with 10 clusters populated\n",
      "In stage 167: transferred 9 clusters with 10 clusters populated\n",
      "In stage 168: transferred 12 clusters with 10 clusters populated\n",
      "In stage 169: transferred 14 clusters with 10 clusters populated\n",
      "In stage 170: transferred 13 clusters with 10 clusters populated\n",
      "In stage 171: transferred 12 clusters with 10 clusters populated\n",
      "In stage 172: transferred 15 clusters with 10 clusters populated\n",
      "In stage 173: transferred 19 clusters with 10 clusters populated\n",
      "In stage 174: transferred 15 clusters with 10 clusters populated\n",
      "In stage 175: transferred 9 clusters with 10 clusters populated\n",
      "In stage 176: transferred 10 clusters with 10 clusters populated\n",
      "In stage 177: transferred 12 clusters with 10 clusters populated\n",
      "In stage 178: transferred 12 clusters with 10 clusters populated\n",
      "In stage 179: transferred 20 clusters with 10 clusters populated\n",
      "In stage 180: transferred 16 clusters with 10 clusters populated\n",
      "In stage 181: transferred 13 clusters with 10 clusters populated\n",
      "In stage 182: transferred 12 clusters with 10 clusters populated\n",
      "In stage 183: transferred 13 clusters with 10 clusters populated\n",
      "In stage 184: transferred 12 clusters with 10 clusters populated\n",
      "In stage 185: transferred 17 clusters with 10 clusters populated\n",
      "In stage 186: transferred 17 clusters with 10 clusters populated\n",
      "In stage 187: transferred 17 clusters with 10 clusters populated\n",
      "In stage 188: transferred 14 clusters with 10 clusters populated\n",
      "In stage 189: transferred 13 clusters with 10 clusters populated\n",
      "In stage 190: transferred 10 clusters with 10 clusters populated\n",
      "In stage 191: transferred 12 clusters with 10 clusters populated\n",
      "In stage 192: transferred 12 clusters with 10 clusters populated\n",
      "In stage 193: transferred 11 clusters with 10 clusters populated\n",
      "In stage 194: transferred 13 clusters with 10 clusters populated\n",
      "In stage 195: transferred 17 clusters with 10 clusters populated\n",
      "In stage 196: transferred 14 clusters with 10 clusters populated\n",
      "In stage 197: transferred 15 clusters with 10 clusters populated\n",
      "In stage 198: transferred 17 clusters with 10 clusters populated\n",
      "In stage 199: transferred 9 clusters with 10 clusters populated\n",
      "Wall time: 3min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(processed_docs,2772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MovieGroupProcess(K=10, alpha=0.1, beta=0.01, n_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 235 clusters with 10 clusters populated\n",
      "In stage 1: transferred 90 clusters with 10 clusters populated\n",
      "In stage 2: transferred 29 clusters with 10 clusters populated\n",
      "In stage 3: transferred 19 clusters with 10 clusters populated\n",
      "In stage 4: transferred 23 clusters with 10 clusters populated\n",
      "In stage 5: transferred 13 clusters with 10 clusters populated\n",
      "In stage 6: transferred 16 clusters with 10 clusters populated\n",
      "In stage 7: transferred 16 clusters with 10 clusters populated\n",
      "In stage 8: transferred 15 clusters with 10 clusters populated\n",
      "In stage 9: transferred 16 clusters with 10 clusters populated\n",
      "In stage 10: transferred 18 clusters with 10 clusters populated\n",
      "In stage 11: transferred 17 clusters with 10 clusters populated\n",
      "In stage 12: transferred 14 clusters with 10 clusters populated\n",
      "In stage 13: transferred 14 clusters with 10 clusters populated\n",
      "In stage 14: transferred 12 clusters with 10 clusters populated\n",
      "In stage 15: transferred 17 clusters with 10 clusters populated\n",
      "In stage 16: transferred 18 clusters with 10 clusters populated\n",
      "In stage 17: transferred 15 clusters with 10 clusters populated\n",
      "In stage 18: transferred 14 clusters with 10 clusters populated\n",
      "In stage 19: transferred 14 clusters with 10 clusters populated\n",
      "In stage 20: transferred 15 clusters with 10 clusters populated\n",
      "In stage 21: transferred 14 clusters with 10 clusters populated\n",
      "In stage 22: transferred 12 clusters with 10 clusters populated\n",
      "In stage 23: transferred 12 clusters with 10 clusters populated\n",
      "In stage 24: transferred 15 clusters with 10 clusters populated\n",
      "In stage 25: transferred 17 clusters with 10 clusters populated\n",
      "In stage 26: transferred 15 clusters with 10 clusters populated\n",
      "In stage 27: transferred 13 clusters with 10 clusters populated\n",
      "In stage 28: transferred 14 clusters with 10 clusters populated\n",
      "In stage 29: transferred 12 clusters with 10 clusters populated\n",
      "In stage 30: transferred 17 clusters with 10 clusters populated\n",
      "In stage 31: transferred 19 clusters with 10 clusters populated\n",
      "In stage 32: transferred 17 clusters with 10 clusters populated\n",
      "In stage 33: transferred 11 clusters with 10 clusters populated\n",
      "In stage 34: transferred 11 clusters with 10 clusters populated\n",
      "In stage 35: transferred 14 clusters with 10 clusters populated\n",
      "In stage 36: transferred 14 clusters with 10 clusters populated\n",
      "In stage 37: transferred 13 clusters with 10 clusters populated\n",
      "In stage 38: transferred 16 clusters with 10 clusters populated\n",
      "In stage 39: transferred 25 clusters with 10 clusters populated\n",
      "In stage 40: transferred 20 clusters with 10 clusters populated\n",
      "In stage 41: transferred 9 clusters with 10 clusters populated\n",
      "In stage 42: transferred 8 clusters with 10 clusters populated\n",
      "In stage 43: transferred 11 clusters with 10 clusters populated\n",
      "In stage 44: transferred 14 clusters with 10 clusters populated\n",
      "In stage 45: transferred 18 clusters with 10 clusters populated\n",
      "In stage 46: transferred 16 clusters with 10 clusters populated\n",
      "In stage 47: transferred 12 clusters with 10 clusters populated\n",
      "In stage 48: transferred 12 clusters with 10 clusters populated\n",
      "In stage 49: transferred 8 clusters with 10 clusters populated\n",
      "In stage 50: transferred 14 clusters with 10 clusters populated\n",
      "In stage 51: transferred 20 clusters with 10 clusters populated\n",
      "In stage 52: transferred 15 clusters with 10 clusters populated\n",
      "In stage 53: transferred 10 clusters with 10 clusters populated\n",
      "In stage 54: transferred 11 clusters with 10 clusters populated\n",
      "In stage 55: transferred 16 clusters with 10 clusters populated\n",
      "In stage 56: transferred 15 clusters with 10 clusters populated\n",
      "In stage 57: transferred 14 clusters with 10 clusters populated\n",
      "In stage 58: transferred 17 clusters with 10 clusters populated\n",
      "In stage 59: transferred 14 clusters with 10 clusters populated\n",
      "In stage 60: transferred 14 clusters with 10 clusters populated\n",
      "In stage 61: transferred 16 clusters with 10 clusters populated\n",
      "In stage 62: transferred 15 clusters with 10 clusters populated\n",
      "In stage 63: transferred 20 clusters with 10 clusters populated\n",
      "In stage 64: transferred 20 clusters with 10 clusters populated\n",
      "In stage 65: transferred 18 clusters with 10 clusters populated\n",
      "In stage 66: transferred 16 clusters with 10 clusters populated\n",
      "In stage 67: transferred 14 clusters with 10 clusters populated\n",
      "In stage 68: transferred 20 clusters with 10 clusters populated\n",
      "In stage 69: transferred 17 clusters with 10 clusters populated\n",
      "In stage 70: transferred 19 clusters with 10 clusters populated\n",
      "In stage 71: transferred 15 clusters with 10 clusters populated\n",
      "In stage 72: transferred 16 clusters with 10 clusters populated\n",
      "In stage 73: transferred 14 clusters with 10 clusters populated\n",
      "In stage 74: transferred 15 clusters with 10 clusters populated\n",
      "In stage 75: transferred 17 clusters with 10 clusters populated\n"
     ]
    }
   ],
   "source": [
    "%time model.fit(processed_docs,2772)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
